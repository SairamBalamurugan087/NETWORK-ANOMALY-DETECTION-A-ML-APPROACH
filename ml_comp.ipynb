{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "seconds = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 20 features selected by the file \"FS_ATTACK.py\" are imported\n",
    "features=[\"Bwd Packet Length Std\",\"Flow Bytes/s\",\"Total Length of Fwd Packets\",\"Fwd Packet Length Std\",\n",
    "\"Flow IAT Std\",\"Flow IAT Min\",\"Fwd IAT Total\",\"Flow Duration\",\"Bwd Packet Length Max\",\"Flow IAT Max\",\n",
    "\"Flow IAT Mean\",\"Total Length of Bwd Packets\",\"Fwd Packet Length Min\",\"Bwd Packet Length Mean\",\n",
    "\"Flow Packets/s\",\"Fwd Packet Length Mean\",\"Total Backward Packets\",\"Total Fwd Packets\",\"Fwd Packet Length Max\",\n",
    "\"Bwd Packet Length Min\",'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('all_data.csv',usecols=features)#CSV rading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Number    Feature           \n",
      "1                 Bwd Packet Length Std\n",
      "2                 Flow Bytes/s     \n",
      "3                 Total Length of Fwd Packets\n",
      "4                 Fwd Packet Length Std\n",
      "5                 Flow IAT Std     \n",
      "6                 Flow IAT Min     \n",
      "7                 Fwd IAT Total    \n",
      "8                 Flow Duration    \n",
      "9                 Bwd Packet Length Max\n",
      "10                Flow IAT Max     \n",
      "11                Flow IAT Mean    \n",
      "12                Total Length of Bwd Packets\n",
      "13                Fwd Packet Length Min\n",
      "14                Bwd Packet Length Mean\n",
      "15                Flow Packets/s   \n",
      "16                Fwd Packet Length Mean\n",
      "17                Total Backward Packets\n",
      "18                Total Fwd Packets\n",
      "19                Fwd Packet Length Max\n",
      "20                Bwd Packet Length Min\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('%-17s %-17s ' % (\"Feature Number\",\"Feature\"))\n",
    "for i in range(len(features)-1):\n",
    "    print ('%-17s %-17s' % (i+1,features[i]))\n",
    "print ('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_or_not=[]\n",
    "for i in df.iloc[:,-1]:\n",
    "    if i ==\"BENIGN\":\n",
    "        attack_or_not.append(1)\n",
    "    else:\n",
    "        attack_or_not.append(0)\n",
    "df.iloc[:,-1]=attack_or_not\n",
    "y = df.iloc[:, -1].values \n",
    "my_list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "least=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML algorithm      Feature Name                   F1-score    Accuracy   Feature List    \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([0], dtype=object),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\21A\\Downloads\\vscode\\AND-ML\\ml_comp.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/21A/Downloads/vscode/AND-ML/ml_comp.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m#machine learning algorithm is applied in this section\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/21A/Downloads/vscode/AND-ML/ml_comp.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m clf \u001b[39m=\u001b[39m ml_list[j]   \u001b[39m#                                                                      \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/21A/Downloads/vscode/AND-ML/ml_comp.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/21A/Downloads/vscode/AND-ML/ml_comp.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m predict \u001b[39m=\u001b[39mclf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/21A/Downloads/vscode/AND-ML/ml_comp.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m f1\u001b[39m=\u001b[39mclf\u001b[39m.\u001b[39mscore(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\21A\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\21A\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:263\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \n\u001b[0;32m    242\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    262\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(y\u001b[39m=\u001b[39my)\n\u001b[1;32m--> 263\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_fit(\n\u001b[0;32m    264\u001b[0m     X, y, np\u001b[39m.\u001b[39;49munique(y), _refit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[0;32m    265\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\21A\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:422\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[39mif\u001b[39;00m _refit:\n\u001b[0;32m    420\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m first_call \u001b[39m=\u001b[39m _check_partial_fit_first_call(\u001b[39mself\u001b[39;49m, classes)\n\u001b[0;32m    423\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, y, reset\u001b[39m=\u001b[39mfirst_call)\n\u001b[0;32m    424\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\21A\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:422\u001b[0m, in \u001b[0;36m_check_partial_fit_first_call\u001b[1;34m(clf, classes)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    416\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m`classes=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m` is not the same as on last call \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mto partial_fit, was: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (classes, clf\u001b[39m.\u001b[39mclasses_)\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    420\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m         \u001b[39m# This is the first call to partial_fit\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m         clf\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m unique_labels(classes)\n\u001b[0;32m    423\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[39m# classes is None and clf.classes_ has already previously been set:\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[39m# nothing to do\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\21A\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:105\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    103\u001b[0m _unique_labels \u001b[39m=\u001b[39m _FN_UNIQUE_LABELS\u001b[39m.\u001b[39mget(label_type, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _unique_labels:\n\u001b[1;32m--> 105\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mrepr\u001b[39m(ys))\n\u001b[0;32m    107\u001b[0m \u001b[39mif\u001b[39;00m is_array_api_compliant:\n\u001b[0;32m    108\u001b[0m     \u001b[39m# array_api does not allow for mixed dtypes\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     unique_ys \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mconcat([_unique_labels(y) \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m ys])\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (array([0], dtype=object),)"
     ]
    }
   ],
   "source": [
    "ml_list={#The machine learning algorithms to be used are defined in a dictionary (ml_list).\n",
    "\"Naive Bayes\":GaussianNB(),\n",
    "\"QDA\":QDA(),\n",
    "##\"Random Forest\":RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "##\"ID3\" :DecisionTreeClassifier(max_depth=5,criterion=\"entropy\"),\n",
    "##\"AdaBoost\":AdaBoostClassifier(),\n",
    "##\"Nearest Neighbors\":KNeighborsClassifier(3),\n",
    "\"MLP\":MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)}\n",
    "\n",
    "\n",
    "features.pop()\n",
    "print ('%-17s %-30s %-10s  %-10s %-15s ' % (\"ML algorithm\",\"Feature Name\",\"F1-score\",\"Accuracy\", \"Feature List\"))# print output header\n",
    "for j in ml_list:\n",
    "    my_list=[]\n",
    "    for i in features:   \n",
    "        my_list.append(i)\n",
    "        X = df.loc[:, my_list].values \n",
    "\n",
    "        ## cross-validation\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "       \n",
    "        #machine learning algorithm is applied in this section\n",
    "        clf = ml_list[j]   #                                                                      \n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1=clf.score(X_test, y_test)\n",
    "        result=f1_score(y_test, predict, average='macro')\n",
    "        accuracy=round(clf.score(X_test, y_test),2)\n",
    "        temp=\"[\"\n",
    "       \n",
    "        for ii in my_list: \n",
    "            temp+=str(my_list.index(ii)+1)+\", \" #translate property list to sequence number for less space\n",
    "\n",
    "       \n",
    "        if result>=least:# If the F-criterion is equal to or greater than the highest value previously accessed, keep the new feature. \n",
    "            least=result\n",
    "            print ('%-17s %-30s %-10s  %-10s %-15s %-15s ' % (j,i,result,accuracy ,temp, \"------> New feature found!!!\"))\n",
    "\n",
    "        else:#If not, remove it from the list\n",
    "            my_list.remove(my_list[len(my_list)-1])\n",
    "            print ('%-17s %-30s %-10s  %-10s %-15s ' % (j,i,result,accuracy ,temp))\n",
    "    print(\"F1=\" ,least,j,\" The most efficient feature list =\",my_list,\"\\n\\n\") #print maximum F1 and the most efficient feature list\n",
    "\n",
    "print(\"operation time: = \",time.time()- seconds ,\"secomds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))\n",
    "\n",
    "# Convert labels to integers if they are in object format\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Example conversion from object to int\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
