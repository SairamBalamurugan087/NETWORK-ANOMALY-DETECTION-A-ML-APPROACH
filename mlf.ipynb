{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Number    Feature           \n",
      "1                 Bwd Packet Length Std\n",
      "2                 Flow Bytes/s     \n",
      "3                 Total Length of Fwd Packets\n",
      "4                 Fwd Packet Length Std\n",
      "5                 Flow IAT Std     \n",
      "6                 Flow IAT Min     \n",
      "7                 Fwd IAT Total    \n",
      "8                 Flow Duration    \n",
      "9                 Bwd Packet Length Max\n",
      "10                Flow IAT Max     \n",
      "11                Flow IAT Mean    \n",
      "12                Total Length of Bwd Packets\n",
      "13                Fwd Packet Length Min\n",
      "14                Bwd Packet Length Mean\n",
      "15                Flow Packets/s   \n",
      "16                Fwd Packet Length Mean\n",
      "17                Total Backward Packets\n",
      "18                Total Fwd Packets\n",
      "19                Fwd Packet Length Max\n",
      "20                Bwd Packet Length Min\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ML algorithm      Feature Name                   F1-score    Accuracy   Feature List    \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([0, 1], dtype=object),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\21A\\Downloads\\vscode\\AND-ML\\mlf.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/21A/Downloads/vscode/AND-ML/mlf.ipynb#W0sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m \u001b[39m#machine learning algorithm is applied in this section\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/21A/Downloads/vscode/AND-ML/mlf.ipynb#W0sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m clf \u001b[39m=\u001b[39m ml_list[j]   \u001b[39m#                                                                       \u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/21A/Downloads/vscode/AND-ML/mlf.ipynb#W0sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/21A/Downloads/vscode/AND-ML/mlf.ipynb#W0sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m predict \u001b[39m=\u001b[39mclf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/21A/Downloads/vscode/AND-ML/mlf.ipynb#W0sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m f1\u001b[39m=\u001b[39mclf\u001b[39m.\u001b[39mscore(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\21A\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\21A\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:263\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \n\u001b[0;32m    242\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    262\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(y\u001b[39m=\u001b[39my)\n\u001b[1;32m--> 263\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_fit(\n\u001b[0;32m    264\u001b[0m     X, y, np\u001b[39m.\u001b[39;49munique(y), _refit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[0;32m    265\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\21A\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:422\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[39mif\u001b[39;00m _refit:\n\u001b[0;32m    420\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m first_call \u001b[39m=\u001b[39m _check_partial_fit_first_call(\u001b[39mself\u001b[39;49m, classes)\n\u001b[0;32m    423\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, y, reset\u001b[39m=\u001b[39mfirst_call)\n\u001b[0;32m    424\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\21A\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:422\u001b[0m, in \u001b[0;36m_check_partial_fit_first_call\u001b[1;34m(clf, classes)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    416\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m`classes=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m` is not the same as on last call \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mto partial_fit, was: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (classes, clf\u001b[39m.\u001b[39mclasses_)\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    420\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m         \u001b[39m# This is the first call to partial_fit\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m         clf\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m unique_labels(classes)\n\u001b[0;32m    423\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[39m# classes is None and clf.classes_ has already previously been set:\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[39m# nothing to do\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\21A\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:105\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    103\u001b[0m _unique_labels \u001b[39m=\u001b[39m _FN_UNIQUE_LABELS\u001b[39m.\u001b[39mget(label_type, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _unique_labels:\n\u001b[1;32m--> 105\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mrepr\u001b[39m(ys))\n\u001b[0;32m    107\u001b[0m \u001b[39mif\u001b[39;00m is_array_api_compliant:\n\u001b[0;32m    108\u001b[0m     \u001b[39m# array_api does not allow for mixed dtypes\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     unique_ys \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mconcat([_unique_labels(y) \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m ys])\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (array([0, 1], dtype=object),)"
     ]
    }
   ],
   "source": [
    "##  \"all_data.csv\" file is required for the operation of the program.\n",
    "##  \"all_data.csv\" file must be located in the same directory as the program.\n",
    "##The intent of this program is to find the optimal property list for Naive Bayes, and QDA and MLP algorithms.\n",
    "##It follows a kind of trial-and-error method.\n",
    "##The feature list obtained from the file \"04_2_feature_selection_for_attack_files.py\" is placed in the machine learning algorithm to start with the highest importance score.\n",
    "##If the F-measure for each feature is equal to or greater than the highest value obtained, this property is added to the list. Otherwise it is removed from the list.\n",
    "##As a result of the process, the program gives the highest F-measure obtained and the property list that provides it\n",
    "##\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%matplotlib inline\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "seconds = time.time()\n",
    "\n",
    "\n",
    "#list of all columns to be imported\n",
    "# the 20 features selected by the file \"04_2_feature_selection_for_attack_files.py\" are used here. (+ Label Feature)\n",
    "features=[\"Bwd Packet Length Std\",\"Flow Bytes/s\",\"Total Length of Fwd Packets\",\"Fwd Packet Length Std\",\n",
    "\"Flow IAT Std\",\"Flow IAT Min\",\"Fwd IAT Total\",\"Flow Duration\",\"Bwd Packet Length Max\",\"Flow IAT Max\",\n",
    "\"Flow IAT Mean\",\"Total Length of Bwd Packets\",\"Fwd Packet Length Min\",\"Bwd Packet Length Mean\",\n",
    "\"Flow Packets/s\",\"Fwd Packet Length Mean\",\"Total Backward Packets\",\"Total Fwd Packets\",\"Fwd Packet Length Max\",\n",
    "\"Bwd Packet Length Min\",'Label']\n",
    "    \n",
    "df=pd.read_csv('all_data.csv',usecols=features)#CSV rading\n",
    "\n",
    "\n",
    "\n",
    "print ('%-17s %-17s ' % (\"Feature Number\",\"Feature\"))# print output header\n",
    "for i in range(len(features)-1):\n",
    "    print ('%-17s %-17s' % (i+1,features[i]))# print features  and feature numbers \n",
    "\n",
    "\n",
    "print ('\\n\\n\\n')\n",
    "\n",
    "attack_or_not=[]\n",
    "for i in df.iloc[:,-1]:\n",
    "    if i ==\"BENIGN\":#it changes the normal label to \"1\" and the attack tag to \"0\" for use in the machine learning algorithm\n",
    "        attack_or_not.append(1)\n",
    "    else:\n",
    "        attack_or_not.append(0)\n",
    "df.iloc[:,-1]=attack_or_not\n",
    "y = df.iloc[:, -1].values #labes-y\n",
    "my_list=[]\n",
    "\n",
    "\n",
    "least=0\n",
    "\n",
    "\n",
    "\n",
    "ml_list={#The machine learning algorithms to be used are defined in a dictionary (ml_list).\n",
    "\"Naive Bayes\":GaussianNB(),\n",
    "\"QDA\":QDA(),\n",
    "##\"Random Forest\":RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "##\"ID3\" :DecisionTreeClassifier(max_depth=5,criterion=\"entropy\"),\n",
    "##\"AdaBoost\":AdaBoostClassifier(),\n",
    "##\"Nearest Neighbors\":KNeighborsClassifier(3),\n",
    "\"MLP\":MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)}\n",
    "\n",
    "\n",
    "features.pop()#the Label tag is removed, no need any more\n",
    "print ('%-17s %-30s %-10s  %-10s %-15s ' % (\"ML algorithm\",\"Feature Name\",\"F1-score\",\"Accuracy\", \"Feature List\"))# print output header\n",
    "for j in ml_list: # run for every machine learning.  \n",
    "    my_list=[]\n",
    "    for i in features: ## run for every  feature  \n",
    "        my_list.append(i)\n",
    "        X = df.loc[:, my_list].values # data\n",
    "\n",
    "        ## cross-validation\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "       \n",
    "        #machine learning algorithm is applied in this section\n",
    "        clf = ml_list[j]   #                                                                       \n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1=clf.score(X_test, y_test)\n",
    "        result=f1_score(y_test, predict, average='macro')\n",
    "        accuracy=round(clf.score(X_test, y_test),2)\n",
    "        temp=\"[\"\n",
    "       \n",
    "        for ii in my_list: \n",
    "            temp+=str(my_list.index(ii)+1)+\", \" #translate property list to sequence number for less space\n",
    "\n",
    "       \n",
    "        if result>=least:# If the F-criterion is equal to or greater than the highest value previously accessed, keep the new feature. \n",
    "            least=result\n",
    "            print ('%-17s %-30s %-10s  %-10s %-15s %-15s ' % (j,i,result,accuracy ,temp, \"------> New feature found!!!\"))\n",
    "\n",
    "        else:#If not, remove it from the list\n",
    "            my_list.remove(my_list[len(my_list)-1])\n",
    "            print ('%-17s %-30s %-10s  %-10s %-15s ' % (j,i,result,accuracy ,temp))\n",
    "    print(\"F1=\" ,least,j,\" The most efficient feature list =\",my_list,\"\\n\\n\") #print maximum F1 and the most efficient feature list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"mission accomplished!\")\n",
    "print(\"operation time: = \",time.time()- seconds ,\"secomds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
